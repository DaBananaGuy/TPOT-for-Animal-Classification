{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPOT Animal Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gTRMsbOfT-HH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, import tpot's `TPOTClassifier`. This will do all of the heavy lifting.\n",
        "\n",
        "We will also use sklearn's `train_test_split` function, as I have yet to find a better option.\n",
        "\n",
        "We will also use pandas for loading the dataset."
      ]
    },
    {
      "metadata": {
        "id": "cta5GdAUVpcq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izce53ftU2sB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tpot import TPOTClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nlLS-sI9U4XY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, load in the dataset using `pd.read_csv`.\n",
        "\n",
        "Also use `iloc` to slect the correct columns."
      ]
    },
    {
      "metadata": {
        "id": "Bu_caW5XVG2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('https://drive.google.com/uc?export=download&id=16-rkk0jXfKVQc-y6WKr8ysD_WLGqdCGq')\n",
        "x_train = data.iloc[:,1:16].values\n",
        "y_train = data.iloc[:,17].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAyS_-XfVIDG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we will create a `TPOTClassifier` and fit it to the data."
      ]
    },
    {
      "metadata": {
        "id": "jW8Wy0YCVTYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "8a7f1d94-b275-4db5-fa83-11f53d4c8d16"
      },
      "cell_type": "code",
      "source": [
        "tpot = TPOTClassifier(generations=5, verbosity=2)\n",
        "tpot.fit(x_train,y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  33%|███▎      | 200/600 [01:35<04:23,  1.52pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.9714285714285715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  50%|█████     | 300/600 [02:28<05:22,  1.08s/pipeline]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 2 - Current best internal CV score: 0.9714285714285715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  67%|██████▋   | 400/600 [03:13<01:41,  1.96pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 3 - Current best internal CV score: 0.9714285714285715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  83%|████████▎ | 500/600 [03:53<00:58,  1.72pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 4 - Current best internal CV score: 0.9714285714285715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 5 - Current best internal CV score: 0.980952380952381\n",
            "\n",
            "Best pipeline: GaussianNB(RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.3, min_samples_leaf=5, min_samples_split=12, n_estimators=100))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "        disable_update_check=False, early_stop=None, generations=5,\n",
              "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "        periodic_checkpoint_folder=None, population_size=100,\n",
              "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
              "        verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "m1d80AL0VWmc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, print the accuracy of the model and export the generated pipline."
      ]
    },
    {
      "metadata": {
        "id": "FR2pKrP4T3Gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2eef86f-badc-4d09-c819-09533b8573e4"
      },
      "cell_type": "code",
      "source": [
        "tpot.score(x_train,y_train)\n",
        "\n",
        "tpot.export('pipeline.py')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "MjJt-9EJWFQ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Here is the generated Pipeline:**"
      ]
    },
    {
      "metadata": {
        "id": "jyAb6EFXWKJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e626704-5e33-46b7-8ffa-8b333ec0f84c"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from tpot.builtins import StackingEstimator\n",
        "\n",
        "data=pd.read_csv('https://drive.google.com/uc?export=download&id=16-rkk0jXfKVQc-y6WKr8ysD_WLGqdCGq')\n",
        "x_train = data.iloc[:,1:16].values\n",
        "y_train = data.iloc[:,17].values\n",
        "\n",
        "exported_pipeline = make_pipeline(\n",
        "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=False, criterion=\"gini\", max_features=0.8, min_samples_leaf=10, min_samples_split=16, n_estimators=100)),\n",
        "    StackingEstimator(estimator=BernoulliNB(alpha=0.1, fit_prior=True)),\n",
        "    LogisticRegression(C=20.0, dual=False, penalty=\"l2\")\n",
        ")\n",
        "\n",
        "exported_pipeline.fit(x_train, y_train)\n",
        "results = exported_pipeline.predict(x_train)\n",
        "\n",
        "def accuracyTest(prediction,ytest):\n",
        "  correctCount = 0\n",
        "  for i in range(len(prediction)):\n",
        "    if(prediction[i]==ytest[i]):\n",
        "      correctCount+=1\n",
        "\n",
        "  print((correctCount/len(ytest))*100)\n",
        "\n",
        "print(accuracyTest(results,y_train))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}